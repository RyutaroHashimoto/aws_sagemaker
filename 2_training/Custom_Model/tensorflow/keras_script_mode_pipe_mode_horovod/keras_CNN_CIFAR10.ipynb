{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<font size=\"7\">Keras simple CNN</font>\n",
    "<br /> \n",
    "\n",
    "    \n",
    "</div>\n",
    "<br />\n",
    "\n",
    "\n",
    "<div style=\"text-align: right;\">\n",
    "<font size=\"4\">2020/11/11</font>\n",
    "<br />\n",
    "<font size=\"4\">Ryutaro Hashimoto</font>\n",
    "</div>\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Setup\" data-toc-modified-id=\"Setup-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Setup</a></span><ul class=\"toc-item\"><li><span><a href=\"#Launching-a-Sagemaker-session\" data-toc-modified-id=\"Launching-a-Sagemaker-session-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Launching a Sagemaker session</a></span></li><li><span><a href=\"#Prepare-the-dataset-for-training\" data-toc-modified-id=\"Prepare-the-dataset-for-training-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Prepare the dataset for training</a></span></li></ul></li><li><span><a href=\"#Train-the-model\" data-toc-modified-id=\"Train-the-model-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Train the model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Specifying-the-Instance-Type\" data-toc-modified-id=\"Specifying-the-Instance-Type-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Specifying the Instance Type</a></span></li><li><span><a href=\"#Setting-for-hyperparameters\" data-toc-modified-id=\"Setting-for-hyperparameters-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Setting for hyperparameters</a></span></li><li><span><a href=\"#Metrics\" data-toc-modified-id=\"Metrics-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Metrics</a></span></li><li><span><a href=\"#Tags\" data-toc-modified-id=\"Tags-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Tags</a></span></li><li><span><a href=\"#Setting-for-estimator\" data-toc-modified-id=\"Setting-for-estimator-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Setting for estimator</a></span></li><li><span><a href=\"#Specify-data-input-and-output\" data-toc-modified-id=\"Specify-data-input-and-output-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>Specify data input and output</a></span></li><li><span><a href=\"#Execute-Training\" data-toc-modified-id=\"Execute-Training-2.7\"><span class=\"toc-item-num\">2.7&nbsp;&nbsp;</span>Execute Training</a></span></li><li><span><a href=\"#Checking-the-accuracy-of-a-model-with-TensorBoard\" data-toc-modified-id=\"Checking-the-accuracy-of-a-model-with-TensorBoard-2.8\"><span class=\"toc-item-num\">2.8&nbsp;&nbsp;</span>Checking the accuracy of a model with TensorBoard</a></span></li></ul></li><li><span><a href=\"#Predict-by-trained-Model\" data-toc-modified-id=\"Predict-by-trained-Model-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Predict by trained Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Deploy-the-trained-model\" data-toc-modified-id=\"Deploy-the-trained-model-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Deploy the trained model</a></span></li><li><span><a href=\"#Invoke-the-endpoint\" data-toc-modified-id=\"Invoke-the-endpoint-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Invoke the endpoint</a></span></li><li><span><a href=\"#Download-the-dataset-for-prediction\" data-toc-modified-id=\"Download-the-dataset-for-prediction-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Download the dataset for prediction</a></span></li><li><span><a href=\"#Prediction\" data-toc-modified-id=\"Prediction-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Prediction</a></span></li><li><span><a href=\"#Accuracy\" data-toc-modified-id=\"Accuracy-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Accuracy</a></span></li><li><span><a href=\"#Confusion-Matrix\" data-toc-modified-id=\"Confusion-Matrix-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>Confusion Matrix</a></span></li></ul></li><li><span><a href=\"#Cleanup\" data-toc-modified-id=\"Cleanup-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Cleanup</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launching a Sagemaker session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "role = 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxx'    # ‚Üê your iam role ARN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the dataset for training\n",
    "\n",
    "Skip the next code since you have already downloaded it."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!python generate_cifar10_tfrecords.py --data-dir ./data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we upload the data to Amazon S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-tutorial-hashimoto/tf-cifar10-example/data'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sagemaker.s3 import S3Uploader\n",
    "\n",
    "bucket = 'sagemaker-tutorial-hashimoto'\n",
    "dataset_uri = S3Uploader.upload('data', 's3://{}/tf-cifar10-example/data'.format(bucket))\n",
    "\n",
    "display(dataset_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specifying the Instance Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_type = 'ml.p2.xlarge'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting for hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {'epochs': 10, 'batch-size': 256}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_definitions = [\n",
    "    {'Name': 'train:loss', 'Regex': '.*loss: ([0-9\\\\.]+) - accuracy: [0-9\\\\.]+.*'},\n",
    "    {'Name': 'train:accuracy', 'Regex': '.*loss: [0-9\\\\.]+ - accuracy: ([0-9\\\\.]+).*'},\n",
    "    {'Name': 'validation:accuracy', 'Regex': '.*step - loss: [0-9\\\\.]+ - accuracy: [0-9\\\\.]+ - val_loss: [0-9\\\\.]+ - val_accuracy: ([0-9\\\\.]+).*'},\n",
    "    {'Name': 'validation:loss', 'Regex': '.*step - loss: [0-9\\\\.]+ - accuracy: [0-9\\\\.]+ - val_loss: ([0-9\\\\.]+) - val_accuracy: [0-9\\\\.]+.*'},\n",
    "    {'Name': 'sec/steps', 'Regex': '.* - \\d+s (\\d+)[mu]s/step - loss: [0-9\\\\.]+ - accuracy: [0-9\\\\.]+ - val_loss: [0-9\\\\.]+ - val_accuracy: [0-9\\\\.]+'}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = [{'Key': 'Project', 'Value': 'cifar10'}, {'Key': 'TensorBoard', 'Value': 'file'}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting for estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "estimator = TensorFlow(entry_point='cifar10_keras_main.py',\n",
    "                       source_dir='source_dir',\n",
    "                       metric_definitions=metric_definitions,\n",
    "                       hyperparameters=hyperparameters,\n",
    "                       role=role,\n",
    "                       framework_version='1.15.2',\n",
    "                       py_version='py3',\n",
    "                       instance_count=1,\n",
    "                       instance_type=instance_type,\n",
    "                       base_job_name='cifar10-tf',\n",
    "                       tags=tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class TensorFlow in module sagemaker.tensorflow.estimator:\n",
      "\n",
      "class TensorFlow(sagemaker.estimator.Framework)\n",
      " |  TensorFlow(py_version=None, framework_version=None, model_dir=None, image_uri=None, distribution=None, **kwargs)\n",
      " |  \n",
      " |  Handle end-to-end training and deployment of user-provided TensorFlow code.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      TensorFlow\n",
      " |      sagemaker.estimator.Framework\n",
      " |      sagemaker.estimator.EstimatorBase\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, py_version=None, framework_version=None, model_dir=None, image_uri=None, distribution=None, **kwargs)\n",
      " |      Initialize a ``TensorFlow`` estimator.\n",
      " |      \n",
      " |      Args:\n",
      " |          py_version (str): Python version you want to use for executing your model training\n",
      " |              code. Defaults to ``None``. Required unless ``image_uri`` is provided.\n",
      " |          framework_version (str): TensorFlow version you want to use for executing your model\n",
      " |              training code. Defaults to ``None``. Required unless ``image_uri`` is provided.\n",
      " |              List of supported versions:\n",
      " |              https://github.com/aws/sagemaker-python-sdk#tensorflow-sagemaker-estimators.\n",
      " |          model_dir (str): S3 location where the checkpoint data and models can be exported to\n",
      " |              during training (default: None). It will be passed in the training script as one of\n",
      " |              the command line arguments. If not specified, one is provided based on\n",
      " |              your training configuration:\n",
      " |      \n",
      " |              * *distributed training with SMDistributed or MPI with Horovod* - ``/opt/ml/model``\n",
      " |              * *single-machine training or distributed training without MPI* -                     ``s3://{output_path}/model``\n",
      " |              * *Local Mode with local sources (file:// instead of s3://)* -                     ``/opt/ml/shared/model``\n",
      " |      \n",
      " |              To disable having ``model_dir`` passed to your training script,\n",
      " |              set ``model_dir=False``.\n",
      " |          image_uri (str): If specified, the estimator will use this image for training and\n",
      " |              hosting, instead of selecting the appropriate SageMaker official image based on\n",
      " |              framework_version and py_version. It can be an ECR url or dockerhub image and tag.\n",
      " |      \n",
      " |              Examples:\n",
      " |                  123.dkr.ecr.us-west-2.amazonaws.com/my-custom-image:1.0\n",
      " |                  custom-image:latest.\n",
      " |      \n",
      " |              If ``framework_version`` or ``py_version`` are ``None``, then\n",
      " |              ``image_uri`` is required. If also ``None``, then a ``ValueError``\n",
      " |              will be raised.\n",
      " |          distribution (dict): A dictionary with information on how to run distributed training\n",
      " |              (default: None). Currently, the following are supported:\n",
      " |              distributed training with parameter servers, SageMaker Distributed (SMD) Data\n",
      " |              and Model Parallelism, and MPI. SMD Model Parallelism can only be used with MPI.\n",
      " |              To enable parameter server use the following setup:\n",
      " |      \n",
      " |              .. code:: python\n",
      " |      \n",
      " |                  {\n",
      " |                      \"parameter_server\": {\n",
      " |                          \"enabled\": True\n",
      " |                      }\n",
      " |                  }\n",
      " |      \n",
      " |              To enable MPI:\n",
      " |      \n",
      " |              .. code:: python\n",
      " |      \n",
      " |                  {\n",
      " |                      \"mpi\": {\n",
      " |                          \"enabled\": True\n",
      " |                      }\n",
      " |                  }\n",
      " |      \n",
      " |              To enable SMDistributed Data Parallel or Model Parallel:\n",
      " |      \n",
      " |              .. code:: python\n",
      " |      \n",
      " |                  {\n",
      " |                      \"smdistributed\": {\n",
      " |                          \"dataparallel\": {\n",
      " |                              \"enabled\": True\n",
      " |                          },\n",
      " |                          \"modelparallel\": {\n",
      " |                              \"enabled\": True,\n",
      " |                              \"parameters\": {}\n",
      " |                          }\n",
      " |                      }\n",
      " |                  }\n",
      " |      \n",
      " |          **kwargs: Additional kwargs passed to the Framework constructor.\n",
      " |      \n",
      " |      .. tip::\n",
      " |      \n",
      " |          You can find additional parameters for initializing this class at\n",
      " |          :class:`~sagemaker.estimator.Framework` and\n",
      " |          :class:`~sagemaker.estimator.EstimatorBase`.\n",
      " |  \n",
      " |  create_model(self, role=None, vpc_config_override='VPC_CONFIG_DEFAULT', entry_point=None, source_dir=None, dependencies=None, **kwargs)\n",
      " |      Create a ``TensorFlowModel`` object that can be used for creating\n",
      " |      SageMaker model entities, deploying to a SageMaker endpoint, or\n",
      " |      starting SageMaker Batch Transform jobs.\n",
      " |      \n",
      " |      Args:\n",
      " |          role (str): The ``TensorFlowModel``, which is also used during transform jobs.\n",
      " |              If not specified, the role from the Estimator is used.\n",
      " |          vpc_config_override (dict[str, list[str]]): Optional override for VpcConfig set on the\n",
      " |              model. Default: use subnets and security groups from this Estimator.\n",
      " |      \n",
      " |              * 'Subnets' (list[str]): List of subnet ids.\n",
      " |              * 'SecurityGroupIds' (list[str]): List of security group ids.\n",
      " |      \n",
      " |          entry_point (str): Path (absolute or relative) to the local Python source file which\n",
      " |              should be executed as the entry point to training. If ``source_dir`` is specified,\n",
      " |              then ``entry_point`` must point to a file located at the root of ``source_dir``.\n",
      " |              If not specified and ``endpoint_type`` is 'tensorflow-serving',\n",
      " |              no entry point is used. If ``endpoint_type`` is also ``None``,\n",
      " |              then the training entry point is used.\n",
      " |          source_dir (str): Path (absolute or relative or an S3 URI) to a directory with any other\n",
      " |              serving source code dependencies aside from the entry point file (default: None).\n",
      " |          dependencies (list[str]): A list of paths to directories (absolute or relative) with\n",
      " |              any additional libraries that will be exported to the container (default: None).\n",
      " |          **kwargs: Additional kwargs passed to\n",
      " |              :class:`~sagemaker.tensorflow.model.TensorFlowModel`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          sagemaker.tensorflow.model.TensorFlowModel: A ``TensorFlowModel`` object.\n",
      " |              See :class:`~sagemaker.tensorflow.model.TensorFlowModel` for full details.\n",
      " |  \n",
      " |  hyperparameters(self)\n",
      " |      Return hyperparameters used by your custom TensorFlow code during model training.\n",
      " |  \n",
      " |  transformer(self, instance_count, instance_type, strategy=None, assemble_with=None, output_path=None, output_kms_key=None, accept=None, env=None, max_concurrent_transforms=None, max_payload=None, tags=None, role=None, volume_kms_key=None, entry_point=None, vpc_config_override='VPC_CONFIG_DEFAULT', enable_network_isolation=None, model_name=None)\n",
      " |      Return a ``Transformer`` that uses a SageMaker Model based on the training job. It\n",
      " |      reuses the SageMaker Session and base job name used by the Estimator.\n",
      " |      \n",
      " |      Args:\n",
      " |          instance_count (int): Number of EC2 instances to use.\n",
      " |          instance_type (str): Type of EC2 instance to use, for example, 'ml.c4.xlarge'.\n",
      " |          strategy (str): The strategy used to decide how to batch records in a single request\n",
      " |              (default: None). Valid values: 'MultiRecord' and 'SingleRecord'.\n",
      " |          assemble_with (str): How the output is assembled (default: None). Valid values: 'Line'\n",
      " |              or 'None'.\n",
      " |          output_path (str): S3 location for saving the transform result. If not specified,\n",
      " |              results are stored to a default bucket.\n",
      " |          output_kms_key (str): Optional. KMS key ID for encrypting the transform output\n",
      " |              (default: None).\n",
      " |          accept (str): The accept header passed by the client to\n",
      " |              the inference endpoint. If it is supported by the endpoint,\n",
      " |              it will be the format of the batch transform output.\n",
      " |          env (dict): Environment variables to be set for use during the transform job\n",
      " |              (default: None).\n",
      " |          max_concurrent_transforms (int): The maximum number of HTTP requests to be made to\n",
      " |              each individual transform container at one time.\n",
      " |          max_payload (int): Maximum size of the payload in a single HTTP request to the\n",
      " |              container in MB.\n",
      " |          tags (list[dict]): List of tags for labeling a transform job. If none specified, then\n",
      " |              the tags used for the training job are used for the transform job.\n",
      " |          role (str): The IAM Role ARN for the ``TensorFlowModel``, which is also used\n",
      " |              during transform jobs. If not specified, the role from the Estimator is used.\n",
      " |          volume_kms_key (str): Optional. KMS key ID for encrypting the volume attached to the ML\n",
      " |              compute instance (default: None).\n",
      " |          entry_point (str): Path (absolute or relative) to the local Python source file which\n",
      " |              should be executed as the entry point to training. If ``source_dir`` is specified,\n",
      " |              then ``entry_point`` must point to a file located at the root of ``source_dir``.\n",
      " |              If not specified and ``endpoint_type`` is 'tensorflow-serving',\n",
      " |              no entry point is used. If ``endpoint_type`` is also ``None``,\n",
      " |              then the training entry point is used.\n",
      " |          vpc_config_override (dict[str, list[str]]): Optional override for\n",
      " |              the VpcConfig set on the model.\n",
      " |              Default: use subnets and security groups from this Estimator.\n",
      " |      \n",
      " |              * 'Subnets' (list[str]): List of subnet ids.\n",
      " |              * 'SecurityGroupIds' (list[str]): List of security group ids.\n",
      " |      \n",
      " |          enable_network_isolation (bool): Specifies whether container will\n",
      " |              run in network isolation mode. Network isolation mode restricts\n",
      " |              the container access to outside networks (such as the internet).\n",
      " |              The container does not make any inbound or outbound network\n",
      " |              calls. If True, a channel named \"code\" will be created for any\n",
      " |              user entry script for inference. Also known as Internet-free mode.\n",
      " |              If not specified, this setting is taken from the estimator's\n",
      " |              current configuration.\n",
      " |          model_name (str): Name to use for creating an Amazon SageMaker\n",
      " |              model. If not specified, the estimator generates a default job name\n",
      " |              based on the training image name and current timestamp.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sagemaker.estimator.Framework:\n",
      " |  \n",
      " |  training_image_uri(self)\n",
      " |      Return the Docker image to use for training.\n",
      " |      \n",
      " |      The :meth:`~sagemaker.estimator.EstimatorBase.fit` method, which does\n",
      " |      the model training, calls this method to find the image to use for model\n",
      " |      training.\n",
      " |      \n",
      " |      Returns:\n",
      " |          str: The URI of the Docker image.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from sagemaker.estimator.Framework:\n",
      " |  \n",
      " |  attach(training_job_name, sagemaker_session=None, model_channel_name='model') from abc.ABCMeta\n",
      " |      Attach to an existing training job.\n",
      " |      \n",
      " |      Create an Estimator bound to an existing training job, each subclass\n",
      " |      is responsible to implement\n",
      " |      ``_prepare_init_params_from_job_description()`` as this method delegates\n",
      " |      the actual conversion of a training job description to the arguments\n",
      " |      that the class constructor expects. After attaching, if the training job\n",
      " |      has a Complete status, it can be ``deploy()`` ed to create a SageMaker\n",
      " |      Endpoint and return a ``Predictor``.\n",
      " |      \n",
      " |      If the training job is in progress, attach will block until the training job\n",
      " |      completes, but logs of the training job will not display. To see the logs\n",
      " |      content, please call ``logs()``\n",
      " |      \n",
      " |      Examples:\n",
      " |          >>> my_estimator.fit(wait=False)\n",
      " |          >>> training_job_name = my_estimator.latest_training_job.name\n",
      " |          Later on:\n",
      " |          >>> attached_estimator = Estimator.attach(training_job_name)\n",
      " |          >>> attached_estimator.logs()\n",
      " |          >>> attached_estimator.deploy()\n",
      " |      \n",
      " |      Args:\n",
      " |          training_job_name (str): The name of the training job to attach to.\n",
      " |          sagemaker_session (sagemaker.session.Session): Session object which\n",
      " |              manages interactions with Amazon SageMaker APIs and any other\n",
      " |              AWS services needed. If not specified, the estimator creates one\n",
      " |              using the default AWS configuration chain.\n",
      " |          model_channel_name (str): Name of the channel where pre-trained\n",
      " |              model data will be downloaded (default: 'model'). If no channel\n",
      " |              with the same name exists in the training job, this option will\n",
      " |              be ignored.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Instance of the calling ``Estimator`` Class with the attached\n",
      " |          training job.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from sagemaker.estimator.Framework:\n",
      " |  \n",
      " |  CONTAINER_CODE_CHANNEL_SOURCEDIR_PATH = '/opt/ml/input/data/code/sourc...\n",
      " |  \n",
      " |  INSTANCE_TYPE = 'sagemaker_instance_type'\n",
      " |  \n",
      " |  LAUNCH_MPI_ENV_NAME = 'sagemaker_mpi_enabled'\n",
      " |  \n",
      " |  LAUNCH_PS_ENV_NAME = 'sagemaker_parameter_server_enabled'\n",
      " |  \n",
      " |  LAUNCH_SM_DDP_ENV_NAME = 'sagemaker_distributed_dataparallel_enabled'\n",
      " |  \n",
      " |  MPI_CUSTOM_MPI_OPTIONS = 'sagemaker_mpi_custom_mpi_options'\n",
      " |  \n",
      " |  MPI_NUM_PROCESSES_PER_HOST = 'sagemaker_mpi_num_of_processes_per_host'\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sagemaker.estimator.EstimatorBase:\n",
      " |  \n",
      " |  compile_model(self, target_instance_family, input_shape, output_path, framework=None, framework_version=None, compile_max_run=900, tags=None, target_platform_os=None, target_platform_arch=None, target_platform_accelerator=None, compiler_options=None, **kwargs)\n",
      " |      Compile a Neo model using the input model.\n",
      " |      \n",
      " |      Args:\n",
      " |          target_instance_family (str): Identifies the device that you want to\n",
      " |              run your model after compilation, for example: ml_c5. For allowed\n",
      " |              strings see\n",
      " |              https://docs.aws.amazon.com/sagemaker/latest/dg/API_OutputConfig.html.\n",
      " |          input_shape (dict): Specifies the name and shape of the expected\n",
      " |              inputs for your trained model in json dictionary form, for\n",
      " |              example: {'data':[1,3,1024,1024]}, or {'var1': [1,1,28,28],\n",
      " |              'var2':[1,1,28,28]}\n",
      " |          output_path (str): Specifies where to store the compiled model\n",
      " |          framework (str): The framework that is used to train the original\n",
      " |              model. Allowed values: 'mxnet', 'tensorflow', 'keras', 'pytorch',\n",
      " |              'onnx', 'xgboost'\n",
      " |          framework_version (str): The version of the framework\n",
      " |          compile_max_run (int): Timeout in seconds for compilation (default:\n",
      " |              3 * 60). After this amount of time Amazon SageMaker Neo\n",
      " |              terminates the compilation job regardless of its current status.\n",
      " |          tags (list[dict]): List of tags for labeling a compilation job. For\n",
      " |              more, see\n",
      " |              https://docs.aws.amazon.com/sagemaker/latest/dg/API_Tag.html.\n",
      " |          target_platform_os (str): Target Platform OS, for example: 'LINUX'.\n",
      " |              For allowed strings see\n",
      " |              https://docs.aws.amazon.com/sagemaker/latest/dg/API_OutputConfig.html.\n",
      " |              It can be used instead of target_instance_family.\n",
      " |          target_platform_arch (str): Target Platform Architecture, for example: 'X86_64'.\n",
      " |              For allowed strings see\n",
      " |              https://docs.aws.amazon.com/sagemaker/latest/dg/API_OutputConfig.html.\n",
      " |              It can be used instead of target_instance_family.\n",
      " |          target_platform_accelerator (str, optional): Target Platform Accelerator,\n",
      " |              for example: 'NVIDIA'. For allowed strings see\n",
      " |              https://docs.aws.amazon.com/sagemaker/latest/dg/API_OutputConfig.html.\n",
      " |              It can be used instead of target_instance_family.\n",
      " |          compiler_options (dict, optional): Additional parameters for compiler.\n",
      " |              Compiler Options are TargetPlatform / target_instance_family specific. See\n",
      " |              https://docs.aws.amazon.com/sagemaker/latest/dg/API_OutputConfig.html for details.\n",
      " |          **kwargs: Passed to invocation of ``create_model()``.\n",
      " |              Implementations may customize ``create_model()`` to accept\n",
      " |              ``**kwargs`` to customize model creation during deploy. For\n",
      " |              more, see the implementation docs.\n",
      " |      \n",
      " |      Returns:\n",
      " |          sagemaker.model.Model: A SageMaker ``Model`` object. See\n",
      " |          :func:`~sagemaker.model.Model` for full details.\n",
      " |  \n",
      " |  delete_endpoint = func(*args, **kwargs)\n",
      " |  \n",
      " |  deploy(self, initial_instance_count, instance_type, serializer=None, deserializer=None, accelerator_type=None, endpoint_name=None, use_compiled_model=False, wait=True, model_name=None, kms_key=None, data_capture_config=None, tags=None, **kwargs)\n",
      " |      Deploy the trained model to an Amazon SageMaker endpoint and return a\n",
      " |      ``sagemaker.Predictor`` object.\n",
      " |      \n",
      " |      More information:\n",
      " |      http://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-training.html\n",
      " |      \n",
      " |      Args:\n",
      " |          initial_instance_count (int): Minimum number of EC2 instances to\n",
      " |              deploy to an endpoint for prediction.\n",
      " |          instance_type (str): Type of EC2 instance to deploy to an endpoint\n",
      " |              for prediction, for example, 'ml.c4.xlarge'.\n",
      " |          serializer (:class:`~sagemaker.serializers.BaseSerializer`): A\n",
      " |              serializer object, used to encode data for an inference endpoint\n",
      " |              (default: None). If ``serializer`` is not None, then\n",
      " |              ``serializer`` will override the default serializer. The\n",
      " |              default serializer is set by the ``predictor_cls``.\n",
      " |          deserializer (:class:`~sagemaker.deserializers.BaseDeserializer`): A\n",
      " |              deserializer object, used to decode data from an inference\n",
      " |              endpoint (default: None). If ``deserializer`` is not None, then\n",
      " |              ``deserializer`` will override the default deserializer. The\n",
      " |              default deserializer is set by the ``predictor_cls``.\n",
      " |          accelerator_type (str): Type of Elastic Inference accelerator to\n",
      " |              attach to an endpoint for model loading and inference, for\n",
      " |              example, 'ml.eia1.medium'. If not specified, no Elastic\n",
      " |              Inference accelerator will be attached to the endpoint. For more\n",
      " |              information:\n",
      " |              https://docs.aws.amazon.com/sagemaker/latest/dg/ei.html\n",
      " |          endpoint_name (str): Name to use for creating an Amazon SageMaker\n",
      " |              endpoint. If not specified, the name of the training job is\n",
      " |              used.\n",
      " |          use_compiled_model (bool): Flag to select whether to use compiled\n",
      " |              (optimized) model. Default: False.\n",
      " |          wait (bool): Whether the call should wait until the deployment of\n",
      " |              model completes (default: True).\n",
      " |          model_name (str): Name to use for creating an Amazon SageMaker\n",
      " |              model. If not specified, the estimator generates a default job name\n",
      " |              based on the training image name and current timestamp.\n",
      " |          kms_key (str): The ARN of the KMS key that is used to encrypt the\n",
      " |              data on the storage volume attached to the instance hosting the\n",
      " |              endpoint.\n",
      " |          data_capture_config (sagemaker.model_monitor.DataCaptureConfig): Specifies\n",
      " |              configuration related to Endpoint data capture for use with\n",
      " |              Amazon SageMaker Model Monitoring. Default: None.\n",
      " |          tags(List[dict[str, str]]): Optional. The list of tags to attach to this specific\n",
      " |              endpoint. Example:\n",
      " |              >>> tags = [{'Key': 'tagname', 'Value': 'tagvalue'}]\n",
      " |              For more information about tags, see\n",
      " |              https://boto3.amazonaws.com/v1/documentation                /api/latest/reference/services/sagemaker.html#SageMaker.Client.add_tags\n",
      " |          **kwargs: Passed to invocation of ``create_model()``.\n",
      " |              Implementations may customize ``create_model()`` to accept\n",
      " |              ``**kwargs`` to customize model creation during deploy.\n",
      " |              For more, see the implementation docs.\n",
      " |      \n",
      " |      Returns:\n",
      " |          sagemaker.predictor.Predictor: A predictor that provides a ``predict()`` method,\n",
      " |              which can be used to send requests to the Amazon SageMaker\n",
      " |              endpoint and obtain inferences.\n",
      " |  \n",
      " |  disable_profiling(self)\n",
      " |      Update the current training job in progress to disable profiling.\n",
      " |      \n",
      " |      Debugger stops collecting the system and framework metrics\n",
      " |      and turns off the Debugger built-in monitoring and profiling rules.\n",
      " |  \n",
      " |  enable_default_profiling(self)\n",
      " |      Update training job to enable Debugger monitoring.\n",
      " |      \n",
      " |      This method enables Debugger monitoring with\n",
      " |      the default ``profiler_config`` parameter to collect system\n",
      " |      metrics and the default built-in ``profiler_report`` rule.\n",
      " |      Framework metrics won't be saved.\n",
      " |      To update training job to emit framework metrics, you can use\n",
      " |      :class:`~sagemaker.estimator.Estimator.update_profiler`\n",
      " |      method and specify the framework metrics you want to enable.\n",
      " |      \n",
      " |      This method is callable when the training job is in progress while\n",
      " |      Debugger monitoring is disabled.\n",
      " |  \n",
      " |  enable_network_isolation(self)\n",
      " |      Return True if this Estimator will need network isolation to run.\n",
      " |      \n",
      " |      Returns:\n",
      " |          bool: Whether this Estimator needs network isolation or not.\n",
      " |  \n",
      " |  fit(self, inputs=None, wait=True, logs='All', job_name=None, experiment_config=None)\n",
      " |      Train a model using the input training dataset.\n",
      " |      \n",
      " |      The API calls the Amazon SageMaker CreateTrainingJob API to start\n",
      " |      model training. The API uses configuration you provided to create the\n",
      " |      estimator and the specified input training data to send the\n",
      " |      CreatingTrainingJob request to Amazon SageMaker.\n",
      " |      \n",
      " |      This is a synchronous operation. After the model training\n",
      " |      successfully completes, you can call the ``deploy()`` method to host the\n",
      " |      model using the Amazon SageMaker hosting services.\n",
      " |      \n",
      " |      Args:\n",
      " |          inputs (str or dict or sagemaker.inputs.TrainingInput): Information\n",
      " |              about the training data. This can be one of three types:\n",
      " |      \n",
      " |              * (str) the S3 location where training data is saved, or a file:// path in\n",
      " |                  local mode.\n",
      " |              * (dict[str, str] or dict[str, sagemaker.inputs.TrainingInput]) If using multiple\n",
      " |                  channels for training data, you can specify a dict mapping channel names to\n",
      " |                  strings or :func:`~sagemaker.inputs.TrainingInput` objects.\n",
      " |              * (sagemaker.inputs.TrainingInput) - channel configuration for S3 data sources\n",
      " |                  that can provide additional information as well as the path to the training\n",
      " |                  dataset.\n",
      " |                  See :func:`sagemaker.inputs.TrainingInput` for full details.\n",
      " |              * (sagemaker.session.FileSystemInput) - channel configuration for\n",
      " |                  a file system data source that can provide additional information as well as\n",
      " |                  the path to the training dataset.\n",
      " |      \n",
      " |          wait (bool): Whether the call should wait until the job completes (default: True).\n",
      " |          logs ([str]): A list of strings specifying which logs to print. Acceptable\n",
      " |              strings are \"All\", \"None\", \"Training\", or \"Rules\". To maintain backwards\n",
      " |              compatibility, boolean values are also accepted and converted to strings.\n",
      " |              Only meaningful when wait is True.\n",
      " |          job_name (str): Training job name. If not specified, the estimator generates\n",
      " |              a default job name based on the training image name and current timestamp.\n",
      " |          experiment_config (dict[str, str]): Experiment management configuration.\n",
      " |              Dictionary contains three optional keys,\n",
      " |              'ExperimentName', 'TrialName', and 'TrialComponentDisplayName'.\n",
      " |  \n",
      " |  get_vpc_config(self, vpc_config_override='VPC_CONFIG_DEFAULT')\n",
      " |      Returns VpcConfig dict either from this Estimator's subnets and\n",
      " |      security groups, or else validate and return an optional override value.\n",
      " |      \n",
      " |      Args:\n",
      " |          vpc_config_override:\n",
      " |  \n",
      " |  latest_job_debugger_artifacts_path(self)\n",
      " |      Gets the path to the DebuggerHookConfig output artifacts.\n",
      " |      \n",
      " |      Returns:\n",
      " |          str: An S3 path to the output artifacts.\n",
      " |  \n",
      " |  latest_job_profiler_artifacts_path(self)\n",
      " |      Gets the path to the profiling output artifacts.\n",
      " |      \n",
      " |      Returns:\n",
      " |          str: An S3 path to the output artifacts.\n",
      " |  \n",
      " |  latest_job_tensorboard_artifacts_path(self)\n",
      " |      Gets the path to the TensorBoardOutputConfig output artifacts.\n",
      " |      \n",
      " |      Returns:\n",
      " |          str: An S3 path to the output artifacts.\n",
      " |  \n",
      " |  logs(self)\n",
      " |      Display the logs for Estimator's training job.\n",
      " |      \n",
      " |      If the output is a tty or a Jupyter cell, it will be color-coded based\n",
      " |      on which instance the log entry is from.\n",
      " |  \n",
      " |  prepare_workflow_for_training(self, job_name=None)\n",
      " |      Calls _prepare_for_training. Used when setting up a workflow.\n",
      " |      \n",
      " |      Args:\n",
      " |          job_name (str): Name of the training job to be created. If not\n",
      " |              specified, one is generated, using the base name given to the\n",
      " |              constructor if applicable.\n",
      " |  \n",
      " |  register(self, content_types, response_types, inference_instances, transform_instances, image_uri=None, model_package_name=None, model_package_group_name=None, model_metrics=None, metadata_properties=None, marketplace_cert=False, approval_status=None, description=None, compile_model_family=None, model_name=None, **kwargs)\n",
      " |      Creates a model package for creating SageMaker models or listing on Marketplace.\n",
      " |      \n",
      " |      Args:\n",
      " |          content_types (list): The supported MIME types for the input data.\n",
      " |          response_types (list): The supported MIME types for the output data.\n",
      " |          inference_instances (list): A list of the instance types that are used to\n",
      " |              generate inferences in real-time.\n",
      " |          transform_instances (list): A list of the instance types on which a transformation\n",
      " |              job can be run or on which an endpoint can be deployed.\n",
      " |          image_uri (str): The container image uri for Model Package, if not specified,\n",
      " |              Estimator's training container image will be used (default: None).\n",
      " |          model_package_name (str): Model Package name, exclusive to `model_package_group_name`,\n",
      " |              using `model_package_name` makes the Model Package un-versioned (default: None).\n",
      " |          model_package_group_name (str): Model Package Group name, exclusive to\n",
      " |              `model_package_name`, using `model_package_group_name` makes the Model Package\n",
      " |              versioned (default: None).\n",
      " |          model_metrics (ModelMetrics): ModelMetrics object (default: None).\n",
      " |          metadata_properties (MetadataProperties): MetadataProperties (default: None).\n",
      " |          marketplace_cert (bool): A boolean value indicating if the Model Package is certified\n",
      " |              for AWS Marketplace (default: False).\n",
      " |          approval_status (str): Model Approval Status, values can be \"Approved\", \"Rejected\",\n",
      " |              or \"PendingManualApproval\" (default: \"PendingManualApproval\").\n",
      " |          description (str): Model Package description (default: None).\n",
      " |          compile_model_family (str): Instance family for compiled model, if specified, a compiled\n",
      " |              model will be used (default: None).\n",
      " |          model_name (str): User defined model name (default: None).\n",
      " |          **kwargs: Passed to invocation of ``create_model()``. Implementations may customize\n",
      " |              ``create_model()`` to accept ``**kwargs`` to customize model creation during\n",
      " |              deploy. For more, see the implementation docs.\n",
      " |      \n",
      " |      Returns:\n",
      " |          str: A string of SageMaker Model Package ARN.\n",
      " |  \n",
      " |  update_profiler(self, rules=None, system_monitor_interval_millis=None, s3_output_path=None, framework_profile_params=None, disable_framework_metrics=False)\n",
      " |      Update training jobs to enable profiling.\n",
      " |      \n",
      " |      This method updates the ``profiler_config`` parameter\n",
      " |      and initiates Debugger built-in rules for profiling.\n",
      " |      \n",
      " |      Args:\n",
      " |          rules (list[:class:`~sagemaker.debugger.ProfilerRule`]): A list of\n",
      " |              :class:`~sagemaker.debugger.ProfilerRule` objects to define\n",
      " |              rules for continuous analysis with SageMaker Debugger. Currently, you can\n",
      " |              only add new profiler rules during the training job. (default: ``None``)\n",
      " |          s3_output_path (str): The location in S3 to store the output. If profiler is enabled\n",
      " |              once, s3_output_path cannot be changed. (default: ``None``)\n",
      " |          system_monitor_interval_millis (int): How often profiling system metrics are\n",
      " |              collected; Unit: Milliseconds (default: ``None``)\n",
      " |          framework_profile_params (:class:`~sagemaker.debugger.FrameworkProfile`):\n",
      " |              A parameter object for framework metrics profiling. Configure it using\n",
      " |              the :class:`~sagemaker.debugger.FrameworkProfile` class.\n",
      " |              To use the default framework profile parameters, pass ``FrameworkProfile()``.\n",
      " |              For more information about the default values,\n",
      " |              see :class:`~sagemaker.debugger.FrameworkProfile`. (default: ``None``)\n",
      " |          disable_framework_metrics (bool): Specify whether to disable all the framework metrics.\n",
      " |              This won't update system metrics and the Debugger built-in rules for monitoring.\n",
      " |              To stop both monitoring and profiling,\n",
      " |              use the :class:`~sagemaker.estimator.Estimator.desable_profiling`\n",
      " |              method. (default: ``False``)\n",
      " |      \n",
      " |      .. attention::\n",
      " |      \n",
      " |          Updating the profiling configuration for TensorFlow dataloader profiling\n",
      " |          is currently not available. If you started a TensorFlow training job only with\n",
      " |          monitoring and want to enable profiling while the training job is running,\n",
      " |          the dataloader profiling cannot be updated.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from sagemaker.estimator.EstimatorBase:\n",
      " |  \n",
      " |  model_data\n",
      " |      str: The model location in S3. Only set if Estimator has been\n",
      " |      ``fit()``.\n",
      " |  \n",
      " |  training_job_analytics\n",
      " |      Return a ``TrainingJobAnalytics`` object for the current training\n",
      " |      job.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sagemaker.estimator.EstimatorBase:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(TensorFlow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify data input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    'train': '{}/train'.format(dataset_uri),\n",
    "    'validation': '{}/validation'.format(dataset_uri),\n",
    "    'eval': '{}/eval'.format(dataset_uri),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-08 06:06:01 Starting - Starting the training job...\n",
      "2021-02-08 06:06:25 Starting - Launching requested ML instancesProfilerReport-1612764359: InProgress\n",
      "......\n",
      "2021-02-08 06:07:32 Starting - Preparing the instances for training........."
     ]
    }
   ],
   "source": [
    "estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the accuracy of a model with TensorBoard\n",
    "\n",
    "Using the visualization tool [TensorBoard](https://www.tensorflow.org/tensorboard), we can compare our training jobs.\n",
    "\n",
    "In a local setting, install TensorBoard with `pip install tensorboard`. Then run the command generated by the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python generate_tensorboard_command.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! AWS_REGION=us-west-2 tensorboard --logdir file:\"s3://sagemaker-us-west-2-005242542034/cifar10-tf-2021-02-08-04-01-54-836/model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running that command, we can access TensorBoard locally at http://localhost:6006.\n",
    "\n",
    "Based on the TensorBoard metrics, we can see that:\n",
    "1. All jobs run for 10 epochs (0 - 9).\n",
    "1. Both File Mode and Pipe Mode run for ~1 minute - Pipe Mode doesn't affect training performance.\n",
    "1. Distributed training runs for only 45 seconds.\n",
    "1. All of the training jobs resulted in similar validation accuracy.\n",
    "\n",
    "This example uses a relatively small dataset (179 MB). For larger datasets, Pipe Mode can significantly reduce training time because it does not copy the entire dataset into local memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict by trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predictor = estimator.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke the endpoint\n",
    "\n",
    "I'll try to generate a random matrix and see if the predictor is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.random.randn(1, 32, 32, 3)\n",
    "print('Predicted class: {}'.format(np.argmax(predictor.predict(data)['predictions'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the dataset for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def predict(data):\n",
    "    predictions = predictor.predict(data)['predictions']\n",
    "    return predictions\n",
    "\n",
    "\n",
    "predicted = []\n",
    "actual = []\n",
    "batches = 0\n",
    "batch_size = 128\n",
    "\n",
    "datagen = ImageDataGenerator()\n",
    "for data in datagen.flow(x_test, y_test, batch_size=batch_size):\n",
    "    for i, prediction in enumerate(predict(data[0])):\n",
    "        predicted.append(np.argmax(prediction))\n",
    "        actual.append(data[1][i][0])\n",
    "\n",
    "    batches += 1\n",
    "    if batches >= len(x_test) / batch_size:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_pred=predicted, y_true=actual)\n",
    "display('Average accuracy: {}%'.format(round(accuracy * 100, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_pred=predicted, y_true=actual)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "sn.set(rc={'figure.figsize': (11.7,8.27)})\n",
    "sn.set(font_scale=1.4)  # for label size\n",
    "sn.heatmap(cm, annot=True, annot_kws={\"size\": 10})  # font size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "To avoid incurring extra charges to your AWS account, let's delete the endpoint we created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "notice": "Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved. Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
